---
title: "Modelo Machine Learning"
author: "Pedro Burgo"
date: "24 de noviembre de 2017"
output:
  html_document:
    highlight: tango
    theme: cerulean
    toc: yes
  pdf_document:
    toc: yes
---

<style type="text/css">

 td {
   font-size: 10px;
}

</style>
```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```
## 1.Introducción

Como ejercicio del Módulo 3 del Master de Big Data de Telefónica, vamos a realizar un Análisis explotatorio basado apoyado en algún método no supervisado para posteriormente llevar a cabo la construcción de al menos 2 modelos *machine learning* supervisados y comparar dichos modelos.
El dataset utilizado, es el que se puede encontran en la siguiente url:
https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip
y la variable a predecir la nota final G3


## 2. Carga de los Datos y Análisis Descriptivo
```{r directorios,  include=FALSE}
getwd()
pathToMain <- "/Users/Casa/Documents/MBD/M3_Tarea"
setwd(pathToMain)
```


```{r funciones}
  # Función que sustituye en las columnas que toman valor yes/no por 1/0
  FromFactorToBinary <- function(dataFrame){
    index <- sapply(dataFrame, is.factor)
    dataFrame[index] <- lapply(dataFrame[index],
                              function(x) if (any(x %in% c("yes","no"))) as.numeric(x) - 1 else x)
    return(dataFrame)
  }

  # Función de personalización de gráficos
  custom_theme <- function(base_size=12,  font=NA) { 
    txt.axis <- element_text(size = base_size - 2, face = "bold", colour = "#2B8BBE")
    txt.legend <- element_text(size = base_size - 4, face = "bold", colour = "#2B8BBE")
    txt.title <- element_text(size = base_size, face = "bold", colour = "#2B8BBE")
    theme_grey(base_size = base_size, base_family = font) + 
    theme(
      plot.title = txt.title,
      legend.title = txt.legend,
      axis.title.x = txt.axis,
      axis.title.y = txt.axis,
      strip.text = txt.legend
      )
  }
  
  # Instalar un package que no existe.
  installRequiredPackages <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[,"Package"])]
    if (length(new.pkg))
      install.packages(new.pkg, dependencies = TRUE)
  }
 

```
```{r setEnviroment }
  # Nombre de los directorios siguiendo el esquema recomendado
  dirPre <- "./Estudio_Preliminar"
  dirFinal <- "./Entrega_Final"
  dirPreData <- paste0(dirPre,"/Datos")
  dirPreFig <- paste0(dirPre,"/Figuras")
  dirPreCode <- paste0(dirPre,"/Codigo")
  dirFinalData <- paste0(dirFinal,"/Datos")
  dirFinalFig <- paste0(dirFinal,"/Figuras")
  dirFinalCode <- paste0(dirFinal,"/Codigo")


  # Se crean los directorios necesarios 
  if (!file.exists(dirPre)) {dir.create(dirPre)}
  if (!file.exists(dirFinal)) {dir.create(dirFinal)}
  if (!file.exists(dirPreData)) {dir.create(dirPreData)}
  if (!file.exists(dirPreFig)) {dir.create(dirPreFig)}
  if (!file.exists(dirPreCode)) {dir.create(dirPreCode)}
  if (!file.exists(dirFinalData)) {dir.create(dirFinalData)}
  if (!file.exists(dirFinalFig)) {dir.create(dirFinalFig)}
  if (!file.exists(dirFinalCode)) {dir.create(dirFinalCode)}

  
  libs <- c("knitr", "dplyr", "ggplot2","RColorBrewer","car","corrplot","arules", "arulesViz",
            "mlbench", "scales", "caret", "ROCR","pROC","rpart","glmnet","gbm","randomForest","plotROC")
  installRequiredPackages(libs)
  
  library(knitr)
  library(plyr)
  library(dplyr)
  library(car)
  library(ggplot2)
```


### 2.1 Carga del dataset original
Descargamos el archivo, lo descomprimimos y leemos el archivo que nos interesa. Vamos a trabajar únicamente con el dataset de la asignatura de portugués.
```{r conexionDatos, echo=TRUE}
  fileURL <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip"
  download.file(fileURL,destfile = paste0(dirPreData,"/student.zip"))
  unzip(paste0(dirPreData,"/student.zip"), exdir=dirPreData)
  conexion <- file(paste0(dirPreData,"/student-por.csv"),"r")
  stPor <- read.csv2(conexion, sep = ";",  header = TRUE )
  close(conexion)
```

### 2.2 Inspección Inicial de los datos
Realizamos una inspección inicial de los datos
```{r summaryMath, echo=TRUE}
  class(stPor)#Comprobamos que se trata de un data.frame

  dim(stPor)#Número de variables y de filas correcto

  any(is.na.data.frame(stPor)) #Vemos si existen NA en la tabla

  names(stPor) <- tolower(names(stPor))
  names(stPor)
  
  kable(head(stPor[,1:10]))
```


### 2.3 Analizamos la distribución de algunas variables

Nuestra variable objetivo va a ser G3, la nota final, no tanto su valor como si el alumno aprueba o no. Para ello, en un inicio, vamos a ver la relación que existe entre algunas de las otras variables y G3.
Primero vamos a crear una serie de variables para trabajar mejor con el dataset

```{r creacionVariables, echo=TRUE, results='asis'}
  # Creamos una serie de variables para ser usadas posteriormente
  stPor$pass <- ifelse(stPor$g3 > 9, 1, 0)# Consideramos el aprobado a partir del 10 sobre 20
  st <- stPor
  st$sex <- ifelse(st$sex == 'M', 1, 0)
  st$famsize <- ifelse(st$famsize == 'LE3', 1 , 0)
  st$school <- ifelse(st$school == 'GP', 1, 0)
  st$address <- ifelse(st$address == '"U', 1, 0)
  st$pstatus <- ifelse(st$pstatus == 'T',1,0)

  levelsParentsEdu <- c("none", "4th grade", "5th-9th grade", "secondary", "high")
  st$fedu.factor <- factor(sapply(st$fedu,  function(x) {
  x <- car::recode(x,"0='none'; 1='4th grade'; 2='5th-9th grade' ; 3='secondary'; 4='high'"); x}), 
        levels = levelsParentsEdu)
  st$medu.factor <- factor(sapply(st$medu,  function(x) {
  x <- car::recode(x,"0='none'; 1='4th grade'; 2='5th-9th grade' ; 3='secondary'; 4='high'"); x}), 
        levels = levelsParentsEdu)
  # Sustituimos las columnas con valor yes/no por 1/0
  st <- FromFactorToBinary(st)
  
  # Convertimos en numéricas las variables que nos faltan
  job.levels <- c('teacher', 'health' , 'services' , 'at_home', 'other')
  st$fjob <- as.integer(st$fjob, levels = job.levels)
  st$mjob <- as.integer(st$mjob, levels = job.levels)
  
  reason.levels <- c('home', 'reputation', 'course', 'other')                          
  st$reason <- as.numeric(st$reason, levels = reason.levels)
  
  guardian.levels <-  c('mother', 'father', 'other')
  st$guardian <- as.numeric(st$guardian, levels = guardian.levels)
  st <- as.data.frame(st)

``` 

### 2.4 Matriz de correlación

 Como punto de partida vamos a estudiar la matriz de correlación usando para ello todas las variables numéricas
 
```{r matrizCorrelacion, results='hold',fig.width=8, fig.height=8, fig.align = 'center'}
  library(corrplot)
  cbPalette <- c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA")
  st.cor  <- select_if(st, is.numeric)
  matCor <- cor(st.cor)
  matCor[is.na(matCor)] <- 0
  col <- colorRampPalette(cbPalette)
  
  png(filename=paste0(dirFinalFig,"/","matriz.png"))
  
  corrplot(matCor, method = "shade", shade.col = NA, tl.col = "black",
           tl.srt = 45, col = col(50), addCoef.col = "black",
           order = "AOE", type = "upper",
           mar = c(0.000000001,0.1,1,1), number.cex = 0.5,cl.cex = 0.7,tl.cex = 0.7,
           title = "Fig 2.7.1 Matriz de Correlación")
  
  dev.off()

```

Se puede apreciar un alto nivel de correlación con el nivel educativo de los padres y una correlación negativa significativa con la variable *failures*

### 2.5 Análisis más detallado de algunas variables

Considerando los resultados de la matriz de correlación, empezamos por observar la distribución del nivel educativo de los padres frente al target con un diagrama de barras. 
Primero con respecto al padre.

```{r plot_padres,  results='hold',fig.width=10, fig.height=5, fig.align = 'center'}
  library(RColorBrewer)
  library(scales)

  edu.labeller <- as_labeller(c("0" = "Suspenso", "1" = "Aprobado"))
  
  plot.data.fedu <- group_by(st, pass) %>%
    mutate(group_size = n()) %>%
    group_by(pass, fedu.factor) %>%
    summarise(perc = n()/max(group_size),count.fedu = n()) 
  
  ggplot(plot.data.fedu, aes(x=fedu.factor, y=count.fedu)) +  
          geom_bar(aes(fill = fedu.factor), stat = "identity") +
          facet_wrap(~pass, labeller = edu.labeller) +
          geom_text(aes(label = paste0(percent(perc), " (", count.fedu, ")")), vjust = -0.5) + 
          ggtitle("Fig 2.5.1 Diagrama barras educación paterna") +   custom_theme() +  
          xlab("Nivel Educación Paterna")  + ylab("Nº de Alumnos") + 
          scale_fill_brewer(name = "Nivel Alcanzado", palette = "GnBu")
  
  ggsave(paste0(dirFinalFig,"/","fedu.png"))
  
```

Lo mismo para el nivel educativo de la madre

```{r plot_madre,  results='hold',fig.width=10, fig.height=5, fig.align = 'center'}
  
  plot.data.medu <- group_by(st, pass) %>%
    mutate(group_size = n()) %>%
    group_by(pass, medu.factor) %>%
    summarise(perc = n()/max(group_size),count.medu = n()) 

  ggplot(plot.data.medu, aes(x=medu.factor, y=count.medu)) +  
          geom_bar(aes(fill = medu.factor), stat = "identity") +
          facet_wrap(~pass, labeller = edu.labeller) +
          geom_text(aes(label = paste0(percent(perc), " (", count.medu, ")")), vjust = -0.5) + 
          ggtitle("Fig 2.5.2 Diagrama barras educación materna") +   custom_theme() + 
          xlab("Nivel Educación Materna")  + ylab("Nº de Alumnos") + 
          scale_fill_brewer(name = "Nivel Alcanzado", palette = "GnBu")
  
  ggsave(paste0(dirFinalFig,"/","medu.png"))

```

Se aprecia en ambos casos, tanto con respecto al padre como a la madre que la proporción de niveles bajos educativos es mayor en el subgrupo de suspensos que en el aprobados. 
Haremos lo mismo para la variable *failures* (fracasos en anteriores asignaturas) que como hemos visto en la matriz de correlación tiene una correlación negativa. 
```{r plot_failures,  results='hold',fig.width=10, fig.height=5, fig.align = 'center'}
  st$failures.factor <- as.factor(sapply(st$failures,  function(x) {
    x <- recode(x,"0='Ninguno'; 1='1 Fracaso'; 2='2 Fracasos' ; 3='3 Fracasos'; 4='4 o más Fracasos '"); x}))

  plot.data.failures <- group_by(st, pass) %>%
      mutate(group_size = n()) %>%
      group_by(pass, failures.factor) %>%
      summarise(perc.failures = n()/max(group_size),count.failures = n()) 
  
  ggplot(plot.data.failures, aes(x=failures.factor, y=count.failures)) +  
        geom_bar(aes(fill = failures.factor), stat = "identity") +
        facet_wrap(~pass, labeller = edu.labeller) +
        geom_text(aes(label = paste0(percent(perc.failures), " (", count.failures, ")")), vjust = -0.5) + 
        ggtitle("Fig 2.5.3 Fracaso en pasadas asignaturas") + custom_theme() +
        xlab("Nº de Fracasos")  + ylab("Nº de Alumnos") + 
        scale_fill_brewer(name = "Nº Fracasos", palette = "GnBu")
  
  ggsave(paste0(dirFinalFig,"/","failures.png"))

```

Vemos que la distribución varía en ambas gráficas, la proporción de alumnos con con fracasos en clases anteriores con respecto a su grupo es considerablemente mayor en aquellos que no han aprobado la asignatura. 


## 3. Análisis exploratorio apoyado en algún método NO Supervisado

Aquí nos vamos a centrar en buscar asociaciones entre algunas de las variables de los estudiantes. En concreto trabajaremos con las variables: *medu.factor*,*fedu.factor*,*famsup* y *pass*. Tratamos de ver si existe asociación entre los niveles educativos de los padres, el soporte familiar a la educación del alumno, y si éste aprueba o no.
Nos valdremos para ello del algoritmo *apriori*, que se usa para la búsqueda de asociaciones entre cualquier conjunto de items.
Se usarán, como decía, los siguientes attibutos:
* medu.factor & fedu.factor(sin estudios, educación elemental
* educación primaria, educación secundaria, educación superior)
* famsup (existencia o ausencia de soporte educacional familiar)
* pass(aprobado, suspenso).

Para ello, vamos a definir las reglas de asociación, que están formadas por uno o más antecedentes (lhs) y una consecuencia (rhs). Las reglas de asociación están definidas por su *soporte* (ratio de los casos en los que se dan los antecentes conjuntamente en el *dataset* completo) y su *confianza*  (ratio de transacciones que conteniendo los antecedentes también contienen el consecuente).
Estudiamos las reglas de asociación estableciendo un soporte del 5% y una confianza del 70%. En este caso en concreto vamos a buscar exclusivamente los antecedentes asociados a la variable *pass*.

```{r apriori, echo=TRUE }
  library(arules)
  library(arulesViz)
  aso.student <- st %>% select(medu.factor, fedu.factor, famsup, pass)
  aso.student <- data.frame(sapply(aso.student, as.factor))
  
  reglas <- apriori(aso.student ,parameter = list( supp = 0.05 , conf = 0.7 , target = "rules"),
                           appearance = list(rhs = c("pass=1", "pass=0"), default = "lhs"))
  
  quality(reglas) <- round(quality(reglas), digits = 3)
  summary(reglas)
  inspect(sort(reglas, by = "lift")[1:10])
```


```{r plotlift,  echo=TRUE,  results='hold', fig.width=5, fig.height=5, fig.align = 'center'}
  png(filename=paste0(dirFinalFig,"/","reglas.png"))
  plot(reglas, method = "grouped", control = list(k = 15, col = heat.colors(10)))
  dev.off() 
```

Se observa un clara asociación entre los niveles educativos altos de los padres y la consecución del aprobado. Esta relación ya asomaba en las distribuciones mostradas en el apartado anterior.

## 4. Construcción de 2 o más modelos de *Machine Learning* supervisados
### 4.1 Selección de variables
Vamos a usar todas las siguientes variables numéricas del dataset:
*age,medu,fedu,traveltime,studytime,failures,famrel,freetime,goout,dalc,walc,health,absences,g1,g2,g3, pass*

```{r seleccionvariables, echo = TRUE}
   st <- st %>%  select(age,medu,fedu,traveltime,studytime,failures,famrel,freetime,goout,dalc,walc,health,absences,g1,g2,g3, pass)
   st$pass <- ifelse(st$pass == '1', 'A', 'S')
   st$pass <- factor(st$pass,levels = c('A', 'S') )
```
Creamos las particiones de los dataset de entrenamiento y test con la libreria *caret*, y comprobamos que las proporciones se mantienen en ambas particiones y  similares a las del dataset original
```{r particiones, echo = TRUE}
  ## Creamos las particiones
  library(mlbench)
  library(caret)
  library(ROCR)
  set.seed(1973)
  index.st <- createDataPartition(st$pass, p = 0.8, list = FALSE)
  train.st <- st[index.st,]
  test.st <- st[ -index.st, ]
  # Train
  prop.table(table(train.st$pass))
  #Test
  prop.table(table(test.st$pass))
```

Buscamos para eliminar con una varianza cercana a cero.
```{r nearzerovariables}

  zero.var.train.index <- nearZeroVar( train.st[,-dim(train.st)[2]], saveMetrics = F )
  colnames(train.st)[zero.var.train.index]
 
```

Ahora buscamos las variables fuertemente correladas también para eliminarlas.
```{r altacorrelacionvariables}
  cor.train.st.matrix <- cor( train.st[, -dim(train.st)[2]] )
  cor.train.st.index <- findCorrelation( cor.train.st.matrix, 0.80 )

  colnames(cor.train.st.matrix)[cor.train.st.index]
  # Las eliminamos 
  cor.train.st <- train.st[,-cor.train.st.index]
  cor.test.st <- test.st[,-cor.train.st.index]

```

Obtenemos las variables *g1* y *g2*
El número de variables predictoras se reduce únicamente en 2
Centramos y escalamos las variables para reducir la desviación con la función preProcess()

```{r preprocess, , echo = TRUE}
  xTrans.st <- preProcess(cor.train.st[, -dim(cor.train.st)[2]]) 
  train.data <- predict( xTrans.st, cor.train.st[,-dim(cor.train.st)[2]])
  train.data$pass <- cor.train.st$pass

  test.data <- predict( xTrans.st, cor.test.st[,-dim(cor.test.st)[2]])
  test.data$pass <- cor.test.st$pass

```

### 4.2 Construcción de modelos

Vamos a construir varios modelos para compararlos posteriormente

#### 4.2.1 Modelo de Regresión Lineal Binaria clásica

```{r glm.model, echo = TRUE}
  library(pROC)
  set.seed(1973)
  #Creamos el modelo
  glm.model <- glm(pass~ . , data = train.data, family = binomial)
  pred.glm.model <- predict(glm.model, newdata = test.data, type = "response")
  #Calculamos el AUC
  roc.glm.model <- pROC::roc(test.data$pass, pred.glm.model)
  auc.glm.model <- pROC::auc(roc.glm.model)
  
```

#### 4.2.2 Classification and Regression Trees (CART)

```{r cart.model, echo = TRUE}
  # Utilizamos validación cruzada como técnica de remuestreo
  control <- trainControl(method = "repeatedcv", repeats = 10, classProbs = TRUE,  summaryFunction = twoClassSummary)
  
  set.seed(1973)
  #Creamos el modelo
  cart.model <- train(pass ~ ., data = train.data, method = "rpart", metric = "ROC", 
                      trControl = control, tuneLength = 5)
  pred.cart.model <- as.vector(predict(cart.model, newdata = test.data, type = "prob")[,"A"])
  
  #Calculamos el AUC
  roc.cart.model <- pROC::roc(test.data$pass, pred.cart.model)
  auc.cart.model <- pROC::auc(roc.cart.model)

```


#### 4.2.3 Regresión Lineal Penalizada (ELASTIC NET)

```{r elastic.model, echo = TRUE}

  set.seed(1973)
  #Creamos el modelo
  elastic.model <- train(pass ~ ., data = train.data, method = "glmnet", metric = "ROC",
                         trControl = control, family = "binomial", tuneLength = 5)
  pred.elastic.model <- as.vector(predict(elastic.model, newdata = test.data, type = "prob")[,"A"])
  #Calculamos el AUC
  roc.elastic.model <- pROC::roc(test.data$pass, pred.elastic.model)
  auc.elastic.model <- pROC::auc(roc.elastic.model)

```


#### 4.2.4 Gradient Boosted Machines (GBM)

```{r gbm.model, echo = TRUE}

  set.seed(1973)
  #Creamos el modelo
  gbm.model <- train(pass ~ ., data = train.data, method = "gbm", metric = "ROC", 
                     trControl = control, verbose = FALSE, tuneLength = 5)
  pred.gbm.model <- as.vector(predict(gbm.model, newdata = test.data, type = "prob")[,"A"])
  #Calculamos el AUC
  roc.gbm.model <- pROC::roc(test.data$pass, pred.gbm.model)
  auc.gbm.model <- pROC::auc(roc.gbm.model)

```

#### 4.2.5 Random Forest

```{r randomf.model, echo = TRUE}

  set.seed(1973)
  #Creamos el modelo
  randomf.model <- train(pass ~ ., data = train.data, method = "rf", metric = "ROC", 
                         trControl = control, verbose = FALSE, tuneLength = 5)
  pred.randomf.model <- as.vector(predict(randomf.model, newdata = test.data, type = "prob")[,"A"])
  #Calculamos el AUC
  roc.randomf.model <- pROC::roc(test.data$pass, pred.randomf.model)
  auc.randomf.model <- pROC::auc(roc.randomf.model)

```


## 5. Comparación de modelos

Creamos un *dataframe* con los valores de las *auc* obtenidas.
```{r evaluacionModelos, echo=TRUE}

   eva.auc <- data.frame(model = c("glm", "cart", "elastic", "gbm","randomf" ),
                         auc = c(auc.glm.model, auc.cart.model, auc.elastic.model, auc.gbm.model,
                                 auc.randomf.model))

  eva.auc <- eva.auc[order(eva.auc$auc, decreasing = TRUE),]#Ordenamos de mayor a menor
  eva.auc$auc <- round(eva.auc$auc, digits = 4)#Redondeamos a 4 dígitos
  eva.auc$model <- factor(eva.auc$model, levels = eva.auc$model)
  eva.auc
  

```

En el siguiente gráfico observamos la AUC que obtenemos de cada uno de los modelos.

```{r evaluacionModelosPlot,  results = 'hold',fig.width = 10, fig.height = 8, fig.align = 'center'}
  
  ggplot(eva.auc, aes(x = model, y = auc), stat = "identity") +
        geom_histogram(aes(fill = auc), stat = "identity", width = 0.7) +
        geom_text(aes(label = auc),colour = "white", fontface = "bold",vjust = +3.0, position = position_dodge(0.9)) + 
        ggtitle("Fig 5.1 Comparación de modelos") +   custom_theme() +  
        xlab("Modelos")  + ylab("Area Bajo la Curva (AUC)")

  ggsave(paste0(dirFinalFig,"/","evaluacion.png"))
```

Se aprecia que el modelo *elastic net* es el que presenta una mayor *AUC*, aunque no con una gran ventaja frente a los modelos que le siguen.